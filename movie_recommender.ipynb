{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import random\n",
    "import requests\n",
    "import xml.sax\n",
    "import subprocess\n",
    "import mwparserfromhell\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from urllib.request import urlretrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download most recent dump (compressed XML file)\n",
    "url = 'https://dumps.wikimedia.org/enwiki-20200820-pages-articles.xml.bz2'\n",
    "\n",
    "urllib.request.urlretrieve(url, './data/enwiki-20200820-pages-articles.xml.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define content handler for XML parser\n",
    "def process_article(title, text):\n",
    "    '''\n",
    "    For each movie we want to extract the name, outgoing links\n",
    "    and properties stored in the infobox.\n",
    "    '''\n",
    "    rotten = [\n",
    "        (re.findall('\\d\\d?\\d?%', p), re.findall('\\d\\.\\d\\/\\d+|$', p), p.lower().find('rotten tomatoes'))\n",
    "        for p in text.split('\\n\\n')\n",
    "    ]\n",
    "    rating = next((\n",
    "        (perc[0], rating[0])\n",
    "        for perc, rating, idx in rotten\n",
    "        if len(perc) == 1 and idx > -1)\n",
    "    , (None, None))\n",
    "    wikicode = mwparserfromhell.parse(text)\n",
    "    film = next((\n",
    "        template\n",
    "        for template in wikicode.filter_templates() \n",
    "        if template.name.strip().lower() == 'infobox film')\n",
    "    , None)\n",
    "    if film:\n",
    "        properties = {\n",
    "            param.name.strip_code().strip(): param.value.strip_code().strip() \n",
    "            for param in film.params\n",
    "            if param.value.strip_code().strip()\n",
    "        }\n",
    "        links = [x.title.strip_code().strip() for x in wikicode.filter_wikilinks()]\n",
    "        return (title, properties, links) + rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiXmlHandler(xml.sax.handler.ContentHandler):\n",
    "    '''\n",
    "    For each <page> tag this collects the contents of the title and of the text into the\n",
    "    self._values dictionary and calls process_article with the collected values.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(WikiXmlHandler, self).__init__()\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._movies = []\n",
    "        self._curent_tag = None\n",
    "\n",
    "    def characters(self, content):\n",
    "        if self._curent_tag:\n",
    "            self._buffer.append(content)\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name in ('title', 'text'):\n",
    "            self._curent_tag = name\n",
    "            self._buffer = []\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == self._curent_tag:\n",
    "            self._values[name] = ' '.join(self._buffer)\n",
    "\n",
    "        if name == 'page':\n",
    "            movie = process_article(**self._values)\n",
    "            if movie:\n",
    "                self._movies.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the compressed dump into the parser:\n",
    "parser = xml.sax.make_parser()\n",
    "handler = WikiXmlHandler()\n",
    "parser.setContentHandler(handler)\n",
    "\n",
    "dump_path = './data/enwiki-20200820-pages-articles.xml.bz2'\n",
    "\n",
    "for line in subprocess.Popen(['bzcat'], stdin = open(dump_path), stdout = subprocess.PIPE).stdout:\n",
    "    try:\n",
    "        parser.feed(line)\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as ndjson\n",
    "with open('./data/wp_movies.ndjson', 'wt') as fout:\n",
    "    for movie in handler._movies:\n",
    "         fout.write(json.dumps(movie) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset from movie-link matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/wp_movies.ndjson') as file:\n",
    "    movies = [json.loads(line) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rotten Tomatoes', 4382),\n",
       " ('The New York Times', 3252),\n",
       " ('Category:American films', 3134),\n",
       " ('Variety (magazine)', 2921),\n",
       " ('Category:English-language films', 2905),\n",
       " ('Metacritic', 2178),\n",
       " ('Roger Ebert', 1863),\n",
       " ('Los Angeles Times', 1757),\n",
       " ('Box Office Mojo', 1756),\n",
       " ('American Film Institute', 1279)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2]) # outgoing links are at this index as a list\n",
    "\n",
    "link_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41105, 4443)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop link types with count < 3\n",
    "top_links = [link for link, count in link_counts.items() if count >= 3]\n",
    "\n",
    "# create an index of links (vocabulary)\n",
    "link_to_idx = {link: i for i, link in enumerate(top_links)}\n",
    "\n",
    "# create an index of movies (vocabulary)\n",
    "movie_to_idx = {movie[0]: i for i, movie in enumerate(movies)}\n",
    "\n",
    "len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453827</th>\n",
       "      <td>17085</td>\n",
       "      <td>4442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453828</th>\n",
       "      <td>995</td>\n",
       "      <td>4442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453829</th>\n",
       "      <td>12778</td>\n",
       "      <td>4442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453830</th>\n",
       "      <td>126</td>\n",
       "      <td>4442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453831</th>\n",
       "      <td>4437</td>\n",
       "      <td>4442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453832 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1  target\n",
       "0           0     0       1\n",
       "1           1     0       1\n",
       "2           2     0       1\n",
       "3           3     0       1\n",
       "4           4     0       1\n",
       "...       ...   ...     ...\n",
       "453827  17085  4442       1\n",
       "453828    995  4442       1\n",
       "453829  12778  4442       1\n",
       "453830    126  4442       1\n",
       "453831   4437  4442       1\n",
       "\n",
       "[453832 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset of link-movie matches (pairs of indices)\n",
    "pairs = []\n",
    "for movie in movies: # 1. for each movie\n",
    "    pairs.extend(\n",
    "        (link_to_idx[link], movie_to_idx[movie[0]]) # 4. save the movie-link pairs (as indices)\n",
    "        for link in movie[2] # 2. check all links\n",
    "        if link in link_to_idx # 3. for all links in vocabulary\n",
    "    )\n",
    "\n",
    "# save also as a set for efficient look-up\n",
    "pairs_set = set(pairs)\n",
    "\n",
    "# create dataframe\n",
    "pairs_df = pd.DataFrame(pairs)\n",
    "pairs_df['target'] = 1\n",
    "\n",
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31705</td>\n",
       "      <td>2509</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34568</td>\n",
       "      <td>2836</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38494</td>\n",
       "      <td>2077</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2419</td>\n",
       "      <td>3973</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24667</td>\n",
       "      <td>3795</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269155</th>\n",
       "      <td>37615</td>\n",
       "      <td>1510</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269156</th>\n",
       "      <td>4163</td>\n",
       "      <td>1968</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269157</th>\n",
       "      <td>7403</td>\n",
       "      <td>3646</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269158</th>\n",
       "      <td>18800</td>\n",
       "      <td>1941</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269159</th>\n",
       "      <td>7068</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2269160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1  target\n",
       "0        31705  2509      -1\n",
       "1        34568  2836      -1\n",
       "2        38494  2077      -1\n",
       "3         2419  3973      -1\n",
       "4        24667  3795      -1\n",
       "...        ...   ...     ...\n",
       "2269155  37615  1510      -1\n",
       "2269156   4163  1968      -1\n",
       "2269157   7403  3646      -1\n",
       "2269158  18800  1941      -1\n",
       "2269159   7068    79      -1\n",
       "\n",
       "[2269160 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 times more negative matches\n",
    "nonpairs = []\n",
    "while len(nonpairs) < 5*len(pairs):\n",
    "    # generate random indices\n",
    "    link_id = random.randrange(len(top_links))\n",
    "    movie_id = random.randrange(len(movie_to_idx))\n",
    "    # check if they are not a match\n",
    "    if (link_id, movie_id) not in pairs_set:\n",
    "        nonpairs.append((link_id, movie_id))\n",
    "        \n",
    "# save also as a set for efficient look-up\n",
    "nonpairs_set = set(nonpairs)\n",
    "\n",
    "# create dataframe\n",
    "nonpairs_df = pd.DataFrame(nonpairs)\n",
    "nonpairs_df['target'] = -1\n",
    "\n",
    "nonpairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722987</th>\n",
       "      <td>37615</td>\n",
       "      <td>1510</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722988</th>\n",
       "      <td>4163</td>\n",
       "      <td>1968</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722989</th>\n",
       "      <td>7403</td>\n",
       "      <td>3646</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722990</th>\n",
       "      <td>18800</td>\n",
       "      <td>1941</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722991</th>\n",
       "      <td>7068</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2722992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         link_id  movie_id  target\n",
       "0              0         0       1\n",
       "1              1         0       1\n",
       "2              2         0       1\n",
       "3              3         0       1\n",
       "4              4         0       1\n",
       "...          ...       ...     ...\n",
       "2722987    37615      1510      -1\n",
       "2722988     4163      1968      -1\n",
       "2722989     7403      3646      -1\n",
       "2722990    18800      1941      -1\n",
       "2722991     7068        79      -1\n",
       "\n",
       "[2722992 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pairs_df, nonpairs_df], axis = 0)\n",
    "df.columns = ['link_id', 'movie_id', 'target']\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1742714, 3)\n",
      "Val: (435679, 3)\n",
      "Test: (544599, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    stratify = df['target'],\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    random_state = 2020\n",
    ")\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    stratify = train_df['target'],\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    random_state = 2020\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "val_df = val_df.reset_index(drop = True)\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "\n",
    "x_train = train_df.loc[:, ['link_id', 'movie_id']]\n",
    "y_train = train_df.loc[:, 'target']\n",
    "\n",
    "x_val = val_df.loc[:, ['link_id', 'movie_id']]\n",
    "y_val = val_df.loc[:, 'target']\n",
    "\n",
    "x_test = test_df.loc[:, ['link_id', 'movie_id']]\n",
    "y_test = test_df.loc[:, 'target']\n",
    "\n",
    "print(f'Train: {train_df.shape}')\n",
    "print(f'Val: {val_df.shape}')\n",
    "print(f'Test: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLATEAU_PATIENCE = 1\n",
    "BATCH_SIZE = 64\n",
    "EARLY_PATIENCE = 3\n",
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):    \n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_1, x_2 = self.inputs.loc[index, 'link_id'], self.inputs.loc[index, 'movie_id']\n",
    "\n",
    "        if self.targets is not None:\n",
    "            y = self.targets.iloc[index]\n",
    "            return (x_1, x_2), y # int64 & int64 ¤ float32\n",
    "        else:\n",
    "            return (x_1, x_2)\n",
    "\n",
    "dataset_train = MovieDataset(x_train, y_train)\n",
    "dataset_val = MovieDataset(x_val, y_val)\n",
    "dataset_test = MovieDataset(x_test, y_test)\n",
    "\n",
    "train_gen = DataLoader(dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_gen = DataLoader(dataset_val, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_gen = DataLoader(dataset_test, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train embeddings using outgoing links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model’s task is to determine whether a certain link can be found on the Wikipedia page of a movie, so we need to feed it labeled examples of matches and non‐matches (y = {-1, 1}). We take both the link_id and the movie_id as a number and feed those into their respective embedding layers. The embedding layer will allocate a vector of embedding_dim for each possible input. We use cosine distance as the loss. The model will learn weights such that this normed dot product will be close to the label. This forces the network to project movies into a space such that similar movies end up in a similar location. We can use this space to find similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieModel(\n",
      "  (movie_embedding): Embedding(4443, 50)\n",
      "  (link_embedding): Embedding(41105, 50)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MovieModel(nn.Module):\n",
    "    def __init__(self, embedding_dim = 50):\n",
    "        super().__init__()\n",
    "        self.movie_embedding = nn.Embedding(len(movie_to_idx), embedding_dim)\n",
    "        self.link_embedding = nn.Embedding(len(top_links), embedding_dim)\n",
    "        \n",
    "    def forward(self, links, movies):\n",
    "        embedded_movies = self.movie_embedding(movies)\n",
    "        embedded_links = self.link_embedding(links)\n",
    "        return embedded_movies, embedded_links\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = MovieModel().to(device)\n",
    "loss_fun = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3, weight_decay = 5e-3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:45<00:00, 258.51it/s]\n",
      "100%|██████████| 6808/6808 [00:10<00:00, 666.17it/s]\n",
      "/home/antti/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type MovieModel. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
      "  0%|          | 1/27230 [00:00<48:08,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | Train loss: 0.2124 | Val loss: 0.2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:43<00:00, 262.68it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 582.16it/s]\n",
      "  0%|          | 1/27230 [00:00<59:39,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 | Train loss: 0.1933 | Val loss: 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:46<00:00, 256.55it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 573.64it/s]\n",
      "  0%|          | 1/27230 [00:00<55:32,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 | Train loss: 0.1738 | Val loss: 0.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:47<00:00, 253.39it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 596.79it/s]\n",
      "  0%|          | 1/27230 [00:00<46:33,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | Train loss: 0.1538 | Val loss: 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:44<00:00, 260.86it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 616.94it/s]\n",
      "  0%|          | 1/27230 [00:00<51:08,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | Train loss: 0.1376 | Val loss: 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:44<00:00, 260.80it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 584.47it/s]\n",
      "  0%|          | 1/27230 [00:00<49:38,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 | Train loss: 0.1277 | Val loss: 0.1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:48<00:00, 250.94it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 584.92it/s]\n",
      "  0%|          | 1/27230 [00:00<54:19,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 | Train loss: 0.1216 | Val loss: 0.1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:45<00:00, 258.16it/s]\n",
      "100%|██████████| 6808/6808 [00:12<00:00, 566.85it/s]\n",
      "  0%|          | 1/27230 [00:00<46:46,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 | Train loss: 0.1171 | Val loss: 0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:49<00:00, 249.57it/s]\n",
      "100%|██████████| 6808/6808 [00:12<00:00, 561.41it/s]\n",
      "  0%|          | 1/27230 [00:00<54:19,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 | Train loss: 0.1136 | Val loss: 0.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:49<00:00, 249.57it/s]\n",
      "100%|██████████| 6808/6808 [00:13<00:00, 520.11it/s]\n",
      "  0%|          | 1/27230 [00:00<1:07:16,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 | Train loss: 0.1106 | Val loss: 0.1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:51<00:00, 244.51it/s]\n",
      "100%|██████████| 6808/6808 [00:12<00:00, 564.79it/s]\n",
      "  0%|          | 1/27230 [00:00<52:07,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 | Train loss: 0.1081 | Val loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:49<00:00, 249.38it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 578.78it/s]\n",
      "  0%|          | 1/27230 [00:00<53:36,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 | Train loss: 0.1061 | Val loss: 0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:43<00:00, 263.43it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 579.02it/s]\n",
      "  0%|          | 1/27230 [00:00<49:27,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 | Train loss: 0.1044 | Val loss: 0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:45<00:00, 258.76it/s]\n",
      "100%|██████████| 6808/6808 [00:11<00:00, 599.59it/s]\n",
      "  0%|          | 1/27230 [00:00<50:24,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 | Train loss: 0.1031 | Val loss: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27230/27230 [01:48<00:00, 250.96it/s]\n",
      "100%|██████████| 6808/6808 [00:12<00:00, 559.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 | Train loss: 0.1021 | Val loss: 0.1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "patience_counter = EARLY_PATIENCE\n",
    "best_val_loss = 999\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode = 'min',\n",
    "    patience = PLATEAU_PATIENCE,\n",
    "    factor = 0.2,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "for i_epoch in range(NUM_EPOCHS):\n",
    "    # ------------- Optimization on training data -------------\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    preds_train = []\n",
    "    labels_train = []\n",
    "    model.train() # set train mode\n",
    "    for ((link_ids, movie_ids), targets) in tqdm(train_gen):\n",
    "        link_ids = link_ids.to(device, dtype = torch.int64)\n",
    "        movie_ids = movie_ids.to(device, dtype = torch.int64)\n",
    "        targets = targets.to(device, dtype = torch.float32)  \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        embedded_links, embedded_movies = model(link_ids, movie_ids)\n",
    "        loss = loss_fun(embedded_links, embedded_movies, targets)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward() # compute gradient\n",
    "        optimizer.step() # update parameters\n",
    "        \n",
    "    # ------------- Evaluation on validation data -------------\n",
    "    preds_val = []\n",
    "    model.eval() # set evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for ((link_ids, movie_ids), targets) in tqdm(val_gen):\n",
    "            link_ids = link_ids.to(device, dtype = torch.int64)\n",
    "            movie_ids = movie_ids.to(device, dtype = torch.int64)\n",
    "            targets = targets.to(device, dtype = torch.float32)  \n",
    "            embedded_links, embedded_movies = model(link_ids, movie_ids)\n",
    "            loss = loss_fun(embedded_links, embedded_movies, targets)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    # ------------- Display progress -------------\n",
    "    print(f'{i_epoch+1} | Train loss: {np.mean(train_losses):.4f} | Val loss: {np.mean(val_losses):.4f}')\n",
    "    \n",
    "    # ------------- Check learning plateau criterion -------------\n",
    "    curr_val_loss = np.mean(val_losses)\n",
    "    scheduler.step(curr_val_loss)\n",
    "    \n",
    "    # ------------- Check early stopping criterion -------------\n",
    "    if curr_val_loss < best_val_loss:\n",
    "        best_val_loss = curr_val_loss\n",
    "        patience_counter = EARLY_PATIENCE # reset patience counter\n",
    "        torch.save(model, './models/model.pth')\n",
    "    else:\n",
    "        patience_counter -= 1\n",
    "        if patience_counter == 0:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm the movie embeddings\n",
    "movie_weights = model.movie_embedding.weight.detach().cpu()\n",
    "movie_norm = movie_weights.norm(p = 2, dim = 1, keepdim = True)\n",
    "normalized_movies = movie_weights.div(movie_norm.expand_as(movie_weights)) # E / E.norm\n",
    "normalized_movies = normalized_movies.numpy()\n",
    "\n",
    "# norm the link embeddings\n",
    "link_weights = model.link_embedding.weight.detach().cpu()\n",
    "link_norm = link_weights.norm(p = 2, dim = 1, keepdim = True)\n",
    "normalized_links = link_weights.div(link_norm.expand_as(link_weights))\n",
    "normalized_links = normalized_links.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_movies(movie):\n",
    "    # get input's cosine simimilarity for all other movies\n",
    "    cosine_sims = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    # save indices of top 10 with smallest distance\n",
    "    closest = np.argsort(cosine_sims)[-10:]\n",
    "    for i in reversed(closest):\n",
    "        print(i, movies[i][0], cosine_sims[i])\n",
    "\n",
    "def similar_links(link):\n",
    "    # get input's cosine simimilarity for all other links\n",
    "    cosine_sims = np.dot(normalized_links, normalized_links[link_to_idx[link]])\n",
    "    # save indices of top 10 with smallest distance\n",
    "    closest = np.argsort(cosine_sims)[-10:]\n",
    "    for i in reversed(closest):\n",
    "        print(i, top_links[i], cosine_sims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Batman Forever 1.0\n",
      "8 Batman (1989 film) 0.9592697\n",
      "10 Batman Returns 0.9484402\n",
      "2052 Batman Begins 0.87854695\n",
      "1177 Ghostbusters 0.865731\n",
      "2421 Ghostbusters II 0.86100507\n",
      "1840 Contact (1997 American film) 0.8562398\n",
      "624 Die Hard 0.8517697\n",
      "1798 Hulk (film) 0.8444223\n",
      "196 Sleepy Hollow (film) 0.8411691\n"
     ]
    }
   ],
   "source": [
    "similar_movies('Batman Forever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222 George Lucas 1.0\n",
      "5848 John Williams 0.9548348\n",
      "2368 Saturn Award for Best Music 0.9440633\n",
      "567 Saturn Award for Best Science Fiction Film 0.9398098\n",
      "5593 Saturn Award for Best Writing 0.9393413\n",
      "3784 Saturn Award for Best Actor 0.9390022\n",
      "466 Raiders of the Lost Ark 0.9385539\n",
      "437 Hugo Award for Best Dramatic Presentation 0.93779016\n",
      "566 Saturn Award for Best Director 0.9321122\n",
      "1637 Jurassic Park (film) 0.9320031\n"
     ]
    }
   ],
   "source": [
    "similar_links('George Lucas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}